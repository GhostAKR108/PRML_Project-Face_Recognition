{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OpBQw8NPiBTM"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbVCYgex9suP"
      },
      "source": [
        "# Fetching Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJYp-RSSiKBk",
        "outputId": "b146ad98-eaf5-4d91-9e6b-2ec995851de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 1288\n",
            "Number of features: 1850\n",
            "Number of classes: 7\n"
          ]
        }
      ],
      "source": [
        "# Fetch LFW dataset with minimum faces per person = 40\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "# Extracting data and target labels\n",
        "X = lfw_people.data\n",
        "y = lfw_people.target\n",
        "target_names = lfw_people.target_names\n",
        "# df = np.genfromtxt('./lfw_people.csv',delimiter=',')\n",
        "# X = df[:, :-1]\n",
        "# y = df[:, -1]\n",
        "n_samples, n_features = X.shape\n",
        "n_classes = len(np.unique(y))\n",
        "\n",
        "# Print dataset statistics\n",
        "print(\"Number of samples: %d\" % n_samples)\n",
        "print(\"Number of features: %d\" % n_features)\n",
        "print(\"Number of classes: %d\" % n_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OFhT6xz6UFo"
      },
      "source": [
        "# Restructuring Image Pixel Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9xzYgxr6erM",
        "outputId": "d34102b7-ab05-401b-8f7e-c16aa14a410b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.9973857  0.99607843 0.9921568  ... 0.29803923 0.24836601 0.20653595]\n",
            " [0.9973857  0.9921569  0.9908497  ... 0.30588236 0.2535948  0.21568628]\n",
            " [0.96078426 0.93071896 0.8679738  ... 0.2875817  0.24183007 0.21568628]\n",
            " ...\n",
            " [0.34509805 0.26143792 0.17385621 ... 0.4248366  0.40261438 0.39084968]\n",
            " [0.30980393 0.23398693 0.17124183 ... 0.39869282 0.4013072  0.3764706 ]\n",
            " [0.28366014 0.2248366  0.18039216 ... 0.38169935 0.38823533 0.3803922 ]]\n"
          ]
        }
      ],
      "source": [
        "img = X[0].reshape((lfw_people.images.shape[1],lfw_people.images.shape[2]))\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "-4ryBUe6iPmi",
        "outputId": "1db4b793-423a-4020-ce5e-fe44638e39f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[254 254 252 ...  76  63  52]\n",
            " [254 253 252 ...  78  64  55]\n",
            " [244 237 221 ...  73  61  55]\n",
            " ...\n",
            " [ 88  66  44 ... 108 102  99]\n",
            " [ 79  59  43 ... 101 102  96]\n",
            " [ 72  57  46 ...  97  99  97]]\n",
            "Hugo Chavez\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Restructuring pixel values to have value between 0 to 255\n",
        "img = (img * 255).astype(np.uint8)\n",
        "print(img)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "print(target_names[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKE1EZF-6sfI"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLLvqZdj1XL",
        "outputId": "b648d3e5-5615-41e5-bf35-babb45793824"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 98.8MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
        "resnet.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqJwMLwZ91_H"
      },
      "source": [
        "# Feature Extraction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QNUirge0oyps"
      },
      "outputs": [],
      "source": [
        "def extract_features(image_arrays, model):\n",
        "    # Load and preprocess the images\n",
        "    preprocessed_images = []\n",
        "    for image_array in image_arrays:\n",
        "        img = image_array.reshape((lfw_people.images.shape[1],lfw_people.images.shape[2]))\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        image = Image.fromarray(img).convert('RGB')\n",
        "        preprocess = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229]),  # Assuming grayscale images\n",
        "        ])\n",
        "        image = preprocess(image)\n",
        "        preprocessed_images.append(image)\n",
        "\n",
        "    # Stack the preprocessed images to create a batch tensor\n",
        "    batch_tensor = torch.stack(preprocessed_images)\n",
        "\n",
        "    # Extract features\n",
        "    with torch.no_grad():\n",
        "        features = model(batch_tensor)\n",
        "\n",
        "    return features\n",
        "\n",
        "# img = X[0].reshape((lfw_people.images.shape[1],lfw_people.images.shape[2]))\n",
        "# img = (img * 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qxDs9FE1sfS",
        "outputId": "18afceff-e8d1-4204-d918-af4c012a3a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1288, 1850)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDAxpuhy95oM"
      },
      "source": [
        "# Batch division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1TfsIdH9r0o6"
      },
      "outputs": [],
      "source": [
        "batch_size = 28\n",
        "\n",
        "X_train_batches = []\n",
        "y_train_batches = []\n",
        "\n",
        "for i in range(int(X.shape[0]/batch_size)):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = (i + 1) * batch_size\n",
        "    batch1 = X[start_idx:end_idx]\n",
        "    batch2 = X[start_idx:end_idx]\n",
        "    X_train_batches.append(batch1)\n",
        "    y_train_batches.append(batch2)\n",
        "\n",
        "X_batches = np.array(X_train_batches)\n",
        "y_batches = np.array(y_train_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnmKVBlrs-aC",
        "outputId": "38ff2168-f1b2-4ca4-9519-ec8df7a3767f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(46, 28, 1850)\n"
          ]
        }
      ],
      "source": [
        "print(X_batches.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx_cL2OL990T"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaflBcydt_3E",
        "outputId": "f304d457-53a4-464d-f3df-a84e746129b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration:  0 \n",
            "\n",
            "Iteration:  1 \n",
            "\n",
            "Iteration:  2 \n",
            "\n",
            "Iteration:  3 \n",
            "\n",
            "Iteration:  4 \n",
            "\n",
            "Iteration:  5 \n",
            "\n",
            "Iteration:  6 \n",
            "\n",
            "Iteration:  7 \n",
            "\n",
            "Iteration:  8 \n",
            "\n",
            "Iteration:  9 \n",
            "\n",
            "Iteration:  10 \n",
            "\n",
            "Iteration:  11 \n",
            "\n",
            "Iteration:  12 \n",
            "\n",
            "Iteration:  13 \n",
            "\n",
            "Iteration:  14 \n",
            "\n",
            "Iteration:  15 \n",
            "\n",
            "Iteration:  16 \n",
            "\n",
            "Iteration:  17 \n",
            "\n",
            "Iteration:  18 \n",
            "\n",
            "Iteration:  19 \n",
            "\n",
            "Iteration:  20 \n",
            "\n",
            "Iteration:  21 \n",
            "\n",
            "Iteration:  22 \n",
            "\n",
            "Iteration:  23 \n",
            "\n",
            "Iteration:  24 \n",
            "\n",
            "Iteration:  25 \n",
            "\n",
            "Iteration:  26 \n",
            "\n",
            "Iteration:  27 \n",
            "\n",
            "Iteration:  28 \n",
            "\n",
            "Iteration:  29 \n",
            "\n",
            "Iteration:  30 \n",
            "\n",
            "Iteration:  31 \n",
            "\n",
            "Iteration:  32 \n",
            "\n",
            "Iteration:  33 \n",
            "\n",
            "Iteration:  34 \n",
            "\n",
            "Iteration:  35 \n",
            "\n",
            "Iteration:  36 \n",
            "\n",
            "Iteration:  37 \n",
            "\n",
            "Iteration:  38 \n",
            "\n",
            "Iteration:  39 \n",
            "\n",
            "Iteration:  40 \n",
            "\n",
            "Iteration:  41 \n",
            "\n",
            "Iteration:  42 \n",
            "\n",
            "Iteration:  43 \n",
            "\n",
            "Iteration:  44 \n",
            "\n",
            "Iteration:  45 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "output = []\n",
        "for i in range(X_batches.shape[0]):\n",
        "  print('Iteration: ', i, '\\n')\n",
        "  features = extract_features(X_batches[i], resnet)\n",
        "  output.append(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVETH-_mxdky"
      },
      "outputs": [],
      "source": [
        "output = np.array(output) #Conversion of list to array\n",
        "output = output.squeeze(3).squeeze(3) #Squeezing last two dimensions to make it a 3-D array\n",
        "output = output.reshape(-1,2048) #Reshaping into a 2-D array\n",
        "torch.save(output, 'extracted_features.pt') #Saving the extracted features in a pt file so that it can be used later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The extracted features have been saved in the 'extracted_features.pt' file."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
