{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OpBQw8NPiBTM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "import torchvision.models as models\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbVCYgex9suP"
      },
      "source": [
        "Fetching Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJYp-RSSiKBk",
        "outputId": "b146ad98-eaf5-4d91-9e6b-2ec995851de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 1288\n",
            "Number of features: 1850\n",
            "Number of classes: 7\n"
          ]
        }
      ],
      "source": [
        "# Fetch LFW dataset with minimum faces per person = 40\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "# Extracting data and target labels\n",
        "X = lfw_people.data\n",
        "y = lfw_people.target\n",
        "target_names = lfw_people.target_names\n",
        "# df = np.genfromtxt('./lfw_people.csv',delimiter=',')\n",
        "# X = df[:, :-1]\n",
        "# y = df[:, -1]\n",
        "n_samples, n_features = X.shape\n",
        "n_classes = len(np.unique(y))\n",
        "\n",
        "# Print dataset statistics\n",
        "print(\"Number of samples: %d\" % n_samples)\n",
        "print(\"Number of features: %d\" % n_features)\n",
        "print(\"Number of classes: %d\" % n_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OFhT6xz6UFo"
      },
      "source": [
        "Restructuring Image Pixel Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9xzYgxr6erM",
        "outputId": "d34102b7-ab05-401b-8f7e-c16aa14a410b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.9973857  0.99607843 0.9921568  ... 0.29803923 0.24836601 0.20653595]\n",
            " [0.9973857  0.9921569  0.9908497  ... 0.30588236 0.2535948  0.21568628]\n",
            " [0.96078426 0.93071896 0.8679738  ... 0.2875817  0.24183007 0.21568628]\n",
            " ...\n",
            " [0.34509805 0.26143792 0.17385621 ... 0.4248366  0.40261438 0.39084968]\n",
            " [0.30980393 0.23398693 0.17124183 ... 0.39869282 0.4013072  0.3764706 ]\n",
            " [0.28366014 0.2248366  0.18039216 ... 0.38169935 0.38823533 0.3803922 ]]\n"
          ]
        }
      ],
      "source": [
        "img = X[0].reshape((lfw_people.images.shape[1],lfw_people.images.shape[2]))\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "-4ryBUe6iPmi",
        "outputId": "1db4b793-423a-4020-ce5e-fe44638e39f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[254 254 252 ...  76  63  52]\n",
            " [254 253 252 ...  78  64  55]\n",
            " [244 237 221 ...  73  61  55]\n",
            " ...\n",
            " [ 88  66  44 ... 108 102  99]\n",
            " [ 79  59  43 ... 101 102  96]\n",
            " [ 72  57  46 ...  97  99  97]]\n",
            "Hugo Chavez\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Restructuring pixel values to have value between 0 to 255\n",
        "img = (img * 255).astype(np.uint8)\n",
        "print(img)\n",
        "plt.imshow(img)\n",
        "print(target_names[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKE1EZF-6sfI"
      },
      "source": [
        "Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLLvqZdj1XL",
        "outputId": "b648d3e5-5615-41e5-bf35-babb45793824"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 98.8MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
        "resnet.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqJwMLwZ91_H"
      },
      "source": [
        "Feature Extraction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QNUirge0oyps"
      },
      "outputs": [],
      "source": [
        "def extract_features(image_arrays, model):\n",
        "    # Load and preprocess the images\n",
        "    preprocessed_images = []\n",
        "    for image_array in image_arrays:\n",
        "        img = image_array.reshape((lfw_people.images.shape[1],lfw_people.images.shape[2]))\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        image = Image.fromarray(img).convert('RGB')\n",
        "        preprocess = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229]),  # Assuming grayscale images\n",
        "        ])\n",
        "        image = preprocess(image)\n",
        "        preprocessed_images.append(image)\n",
        "\n",
        "    # Stack the preprocessed images to create a batch tensor\n",
        "    batch_tensor = torch.stack(preprocessed_images)\n",
        "\n",
        "    # Extract features\n",
        "    with torch.no_grad():\n",
        "        features = model(batch_tensor)\n",
        "\n",
        "    return features\n",
        "\n",
        "# img = X[0].reshape((lfw_people.images.shape[1],lfw_people.images.shape[2]))\n",
        "# img = (img * 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qxDs9FE1sfS",
        "outputId": "18afceff-e8d1-4204-d918-af4c012a3a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1288, 1850)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDAxpuhy95oM"
      },
      "source": [
        "Batch division"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1TfsIdH9r0o6"
      },
      "outputs": [],
      "source": [
        "batch_size = 28\n",
        "\n",
        "X_train_batches = []\n",
        "y_train_batches = []\n",
        "\n",
        "for i in range(int(X.shape[0]/batch_size)):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = (i + 1) * batch_size\n",
        "    batch1 = X[start_idx:end_idx]\n",
        "    batch2 = X[start_idx:end_idx]\n",
        "    X_train_batches.append(batch1)\n",
        "    y_train_batches.append(batch2)\n",
        "\n",
        "X_batches = np.array(X_train_batches)\n",
        "y_batches = np.array(y_train_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnmKVBlrs-aC",
        "outputId": "38ff2168-f1b2-4ca4-9519-ec8df7a3767f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(46, 28, 1850)\n"
          ]
        }
      ],
      "source": [
        "print(X_batches.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx_cL2OL990T"
      },
      "source": [
        "Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaflBcydt_3E",
        "outputId": "f304d457-53a4-464d-f3df-a84e746129b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration:  0 \n",
            "\n",
            "Iteration:  1 \n",
            "\n",
            "Iteration:  2 \n",
            "\n",
            "Iteration:  3 \n",
            "\n",
            "Iteration:  4 \n",
            "\n",
            "Iteration:  5 \n",
            "\n",
            "Iteration:  6 \n",
            "\n",
            "Iteration:  7 \n",
            "\n",
            "Iteration:  8 \n",
            "\n",
            "Iteration:  9 \n",
            "\n",
            "Iteration:  10 \n",
            "\n",
            "Iteration:  11 \n",
            "\n",
            "Iteration:  12 \n",
            "\n",
            "Iteration:  13 \n",
            "\n",
            "Iteration:  14 \n",
            "\n",
            "Iteration:  15 \n",
            "\n",
            "Iteration:  16 \n",
            "\n",
            "Iteration:  17 \n",
            "\n",
            "Iteration:  18 \n",
            "\n",
            "Iteration:  19 \n",
            "\n",
            "Iteration:  20 \n",
            "\n",
            "Iteration:  21 \n",
            "\n",
            "Iteration:  22 \n",
            "\n",
            "Iteration:  23 \n",
            "\n",
            "Iteration:  24 \n",
            "\n",
            "Iteration:  25 \n",
            "\n",
            "Iteration:  26 \n",
            "\n",
            "Iteration:  27 \n",
            "\n",
            "Iteration:  28 \n",
            "\n",
            "Iteration:  29 \n",
            "\n",
            "Iteration:  30 \n",
            "\n",
            "Iteration:  31 \n",
            "\n",
            "Iteration:  32 \n",
            "\n",
            "Iteration:  33 \n",
            "\n",
            "Iteration:  34 \n",
            "\n",
            "Iteration:  35 \n",
            "\n",
            "Iteration:  36 \n",
            "\n",
            "Iteration:  37 \n",
            "\n",
            "Iteration:  38 \n",
            "\n",
            "Iteration:  39 \n",
            "\n",
            "Iteration:  40 \n",
            "\n",
            "Iteration:  41 \n",
            "\n",
            "Iteration:  42 \n",
            "\n",
            "Iteration:  43 \n",
            "\n",
            "Iteration:  44 \n",
            "\n",
            "Iteration:  45 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "output = []\n",
        "for i in range(X_batches.shape[0]):\n",
        "  print('Iteration: ', i, '\\n')\n",
        "  features = extract_features(X_batches[i], resnet)\n",
        "  output.append(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVETH-_mxdky"
      },
      "outputs": [],
      "source": [
        "output = np.array(output) #Conversion of list to array\n",
        "output = output.squeeze(3).squeeze(3) #Squeezing last two dimensions to make it a 3-D array\n",
        "output = output.reshape(-1,2048) #Reshaping into a 2-D array\n",
        "torch.save(output, 'extracted_features.pt') #Saving the extracted features in a pt file so that it can be used later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VchxPAnK8Z3d"
      },
      "source": [
        "Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SIyMZvV15H9H"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(output, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcHV0xfg8cPh"
      },
      "source": [
        "Classification: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXXHF4yT0KjS",
        "outputId": "b7fd598e-c12b-45d2-fca9-7663d1efd587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic Regression:  0.9031007751937985\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter = 2000)\n",
        "model.fit(X_train, Y_train)\n",
        "print(\"Accuracy of Logistic Regression: \",model.score(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi30T5dw8guL"
      },
      "source": [
        "Creating a train-test split of original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HbLmcrYb5gl9"
      },
      "outputs": [],
      "source": [
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZulKEXx8k5B"
      },
      "source": [
        "Accuracy of Logistic Regression on Original Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm5aSyzR1YXk",
        "outputId": "1df17715-2ea8-46ff-a09a-eb8e11d69d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Logistic Regression:  0.8255813953488372\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression(max_iter = 2000)\n",
        "model.fit(X_train2, Y_train2)\n",
        "print(\"Accuracy of Logistic Regression: \",model.score(X_test2, Y_test2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
